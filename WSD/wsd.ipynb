{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esercitazione WSD \n",
    "\n",
    "Consegna 1\n",
    "\n",
    "Mario Scapellato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import semcor as corpus\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "from nltk.wsd import lesk\n",
    "from nltk.corpus.reader import Lemma\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implemento l'algoritmo di Lesk. Il significato corretto di ogni parola viene trovato ottenendo il senso che si sovrappone maggiormente\n",
    "# tra il contesto dato  e il suo significato nel dizionario\n",
    "\n",
    "def the_lesk(word,sentence):\n",
    "    best_sense = []\n",
    "    max_overlap = 0\n",
    "\n",
    "    ctx = set(sentence) #setto il contesto  \n",
    "    for synset in wn.synsets(word): \n",
    "        signature = synset.definition().lower().split() #setto la definizione del senso\n",
    "        for example in synset.examples(): \n",
    "            signature += example.lower().split() #aggiorno la definizione del senso con gli esempi\n",
    "        signature = set(signature) #setto la definizione del senso\n",
    "        overlap = signature.intersection(ctx) #overlappo la signature e il contesto del termine polisemico\n",
    "        #massimizzo l'overlap\n",
    "        if len(overlap) > max_overlap:\n",
    "            max_overlap = len(overlap)\n",
    "            best_sense = synset\n",
    "    return best_sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estraggo le frasi dal corpus semcor e le salvo in una lista\n",
    "def get_sentence_from_semcor(sentence_num):\n",
    "   sentences, senses = [], []\n",
    "   for index in range(0,(sentence_num)):\n",
    "      #index = np.random.randint(0,sentence_num)\n",
    "      for node in corpus.tagged_sents(tag='both')[index]:\n",
    "         node_noun = None\n",
    "         # If node is a noun\n",
    "         #prendo un sostantivo per frase da disambiguare\n",
    "         if isinstance(node.label(), Lemma) and node[0].label() == 'NN':\n",
    "            node_noun = node\n",
    "            break\n",
    "      if node_noun:\n",
    "         senses.append(node)\n",
    "         sentences.append(\" \".join(corpus.sents()[index]))\n",
    "   return sentences, senses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eseguo l'algoritmo di Lesk e calcolo l'accuratezza sia della WSD per il corpus con l'algoritmo di Lesk implementato da me che con quello di nltk\n",
    "def execution(size_sentence):\n",
    "    result=[] \n",
    "    result_nltk = []\n",
    "    sentences, noun = get_sentence_from_semcor(size_sentence)\n",
    "    target = [str(w.label().synset()) for w in noun] \n",
    "    for i in range(len(noun)):\n",
    "        word =  re.sub(r'[^\\w\\s]', '', noun[i][0][0])\n",
    "        #disambiguo un sostantivo per frase\n",
    "        disambiguation = the_lesk(word, sentences[i])\n",
    "        lesk_result_nltk = lesk(sentences[i], word)\n",
    "        result.append(str(disambiguation))\n",
    "        result_nltk.append(str(lesk_result_nltk))\n",
    "\n",
    "    \n",
    "    print(\"WSD accuracy for Corpus with Lesk ALgorithm implemented: {:.0f}%\\n\".format(accuracy_score(target, result) * 100))\n",
    "    print(\"WSD of nltk lesk: {:.0f}%\".format(accuracy_score(target, result_nltk) * 100))\n",
    "    print()\n",
    "\n",
    "    return result, result_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WSD accuracy for Corpus with Lesk ALgorithm implemented: 48%\n",
      "\n",
      "WSD of nltk lesk: 38%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = 50\n",
    "score = execution(sentences)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_random_from_semcor(sentence_num):\n",
    "   sentences, senses = [], []\n",
    "   random_index = np.random.randint(0,(sentence_num)) #indice random e poi mi comporto come prima\n",
    "   for index in range(0,(random_index)): \n",
    "      for node in corpus.tagged_sents(tag='both')[index]:\n",
    "         node_noun = None\n",
    "         # If node is a noun\n",
    "         #prendo un sostantivo per frase da disambiguare\n",
    "         if isinstance(node.label(), Lemma) and node[0].label() == 'NN':\n",
    "            node_noun = node\n",
    "            break\n",
    "      if node_noun:\n",
    "         senses.append(node)\n",
    "         sentences.append(\" \".join(corpus.sents()[index]))\n",
    "   return sentences, senses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#esecuzione uguale a prima ma con frasi random\n",
    "def execution_random(sentences):\n",
    "    result=[]\n",
    "    result_nltk = []\n",
    "    sentences, noun = get_sentence_random_from_semcor(sentences)\n",
    "    target = [str(w.label().synset()) for w in noun] #il target e' il senso corretto del sostantivo\n",
    "    for i in range(len(noun)):\n",
    "        word =  re.sub(r'[^\\w\\s]', '', noun[i][0][0])\n",
    "        #disambiguo un sostantivo per frase\n",
    "        disambiguation = the_lesk(word, sentences[i])\n",
    "        lesk_result_nltk = lesk(sentences[i], word)\n",
    "        result.append(str(disambiguation))\n",
    "        result_nltk.append(str(lesk_result_nltk))\n",
    "        \n",
    "    print(\"WSD accuracy for Corpus with Lesk ALgorithm implemented: {:.0f}%\\n\".format(accuracy_score(target, result) * 100))\n",
    "    print(\"WSD of nltk lesk: {:.0f}%\".format(accuracy_score(target, result_nltk) * 100))\n",
    "    print()\n",
    "\n",
    "    \n",
    "    return result, result_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: \n",
      "WSD accuracy for Corpus with Lesk ALgorithm implemented: 40%\n",
      "\n",
      "WSD of nltk lesk: 30%\n",
      "\n",
      "------------------------------------\n",
      "Iteration 1: \n",
      "WSD accuracy for Corpus with Lesk ALgorithm implemented: 36%\n",
      "\n",
      "WSD of nltk lesk: 28%\n",
      "\n",
      "------------------------------------\n",
      "Iteration 2: \n",
      "WSD accuracy for Corpus with Lesk ALgorithm implemented: 51%\n",
      "\n",
      "WSD of nltk lesk: 41%\n",
      "\n",
      "------------------------------------\n",
      "Iteration 3: \n",
      "WSD accuracy for Corpus with Lesk ALgorithm implemented: 47%\n",
      "\n",
      "WSD of nltk lesk: 38%\n",
      "\n",
      "------------------------------------\n",
      "Iteration 4: \n",
      "WSD accuracy for Corpus with Lesk ALgorithm implemented: 46%\n",
      "\n",
      "WSD of nltk lesk: 37%\n",
      "\n",
      "------------------------------------\n",
      "Iteration 5: \n",
      "WSD accuracy for Corpus with Lesk ALgorithm implemented: 40%\n",
      "\n",
      "WSD of nltk lesk: 30%\n",
      "\n",
      "------------------------------------\n",
      "Iteration 6: \n",
      "WSD accuracy for Corpus with Lesk ALgorithm implemented: 47%\n",
      "\n",
      "WSD of nltk lesk: 37%\n",
      "\n",
      "------------------------------------\n",
      "Iteration 7: \n",
      "WSD accuracy for Corpus with Lesk ALgorithm implemented: 47%\n",
      "\n",
      "WSD of nltk lesk: 37%\n",
      "\n",
      "------------------------------------\n",
      "Iteration 8: \n",
      "WSD accuracy for Corpus with Lesk ALgorithm implemented: 38%\n",
      "\n",
      "WSD of nltk lesk: 27%\n",
      "\n",
      "------------------------------------\n",
      "Iteration 9: \n",
      "WSD accuracy for Corpus with Lesk ALgorithm implemented: 49%\n",
      "\n",
      "WSD of nltk lesk: 42%\n",
      "\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#faccio 10 iterazioni\n",
    "for i in range(10):\n",
    "    print(\"Iteration {}: \".format(i))\n",
    "    accuracy_random = execution_random(sentences)\n",
    "    print(\"------------------------------------\")\n",
    "\n",
    "#print(\"Mean Random: \", len(accuracy_random)/10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8713ca3b77628a4414cb19afecce4be886be5a2f883480e0c3ed66d57c8d45ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
